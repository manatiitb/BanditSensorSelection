%!TEX root =  main.tex
Let $\TSA$ be the set of all stochastic, cascaded sensor acquisition problems. 
Thus, $\theta \in \TSA$ such that if $Y\sim \theta$ then $\gamma_k(\theta):=\Prob{Y\ne Y^k}$ 
is a decreasing sequence.
Given a subset $\Theta\subset \TSA$, we say that $\Theta$ is \emph{learnable} 
if there exists a learning algorithm $\Alg$ such that
for any $\theta\in \Theta$, the expected regret $\EE{ \Regret_n(\Alg,\theta) }$ 
of algorithm $\Alg$ on instance $\theta$ is sublinear.
A subset $\Theta$ is said to be a maximal learnable problem class if it is learnable and for any $\Theta'\subset \TSA$ superset
of $\Theta$, $\Theta'$ is not learnable.
In this section we study two special learnable problem classes, $\TSD\subset \TWD$, where the regularity properties of the instances in $\TSD$ are more intuitive, while $\TWD$ can be seen as a maximal extension of $\TSD$.

Let us start with some definitions.
Given an instance $\theta \in \TSA$, we can decompose $\theta$ (or $P$) into the joint distribution $P_S$ of the sensor outputs $S = (Y^1,\dots,Y^k)$ and the conditional distribution of the state of the environment, given the sensor outputs, $P_{Y|S}$.
Specifically, letting $(Y,S)\sim P$, for $s\in \{0,1\}^K$ and $y\in \{0,1\}$, $P_S(s) = \Prob{S = s}$ and $P_{Y|S}(y|s) = \Prob{Y=y|S=s}$. We denote this by $P = P_S \otimes P_{Y|S}$.
A learner who observes the output of all sensors for long enough is able to identify 
$P_S$ with arbitrary precision, while $P_{Y|S}$ remains hidden from the learner.
%A problem set $\Theta$ is said to be complete if $\{P_S\,:\, \exists P\in \Theta \text{ s.t. } P = P_S \otimes P_{Y|S} \}=M_1( \{0,1\}^K )$, i.e., all distributions over the sensor outputs are possible under some problem instance in $\Theta$.
 This leads to the following statement:
\begin{prop}
\label{prop:learnablemap}
%Let $\Theta \subset \TSA$ be complete. Then,
A subset $\Theta\subset \TSA$ is learnable 
if and only if there exists a map $a: M_1( \{0,1\}^K )\to [K]$ such that 
for any $\theta \in \Theta$ 
with decomposition $P = P_S \otimes P_{Y|S}$, $a(P_S)$ is an optimal action in $\theta$.
\end{prop}


An action selection map  $a: M_1( \{0,1\}^K ) \to [K]$ is said to be \emph{sound} for an instance 
$\theta\in \TSA$ with $\theta = P_S\otimes P_{Y|S}$ if $a(P_S)$ selects an optimal action in $\theta$.
With this terminology, the previous proposition says that a set of instances $\Theta$ is learnable if and only if there exists a
sound action selection map for all the instances in $\Theta$.

A class of sensor acquisition problems that contains instances that satisfy the so-called \emph{strong dominance} condition 
will be shown to be learnable:
\begin{defi}[Strong Dominance]
	An instance $\theta \in \TSA$  is said to satisfy the \emph{strong dominance property} if 
	it holds in the instance that if a sensor predicts correctly
	then all the sensors in the subsequent stages of the cascade also predict correctly, i.e., 
	for any $i\in [K]$,
	\begin{equation}
	\label{eqn:DominanceCondition}
	Y^i=Y \,\, \Rightarrow\,\, Y^{i+1}= \dots =  Y^K = Y
	\end{equation}
	almost surely (a.s.)
	where $(Y,Y^1,\dots,Y^K)\sim P$.
\end{defi}
\begin{table}[h]
\begin{center}
\begin{tabular}[c]{c|c|c|c } 
%	\caption{cap:Error statistics}
dataset & $\gamma_1$ & $\gamma_2$ & $\delta_{12}$\\ \hline \hline
diabetic & $0.288 $ & $ 0.219$  & 0.075\\  \hline
heart & $0.305$ & $0.169$ &  0.051\\  \hline
\end{tabular}
\label{tab:ErrorTable1}
\caption{Error statistics}
\end{center}
\end{table}
Before we develop this concept further we will motivate strong dominance based on experiments on a few real-world datasets. Table \ref{tab:ErrorTable1} lists the error probabilities of the classifiers (sensors) for the heart and diabetic datasets from UCI repository. For both the datasets, $\gamma_1$ denotes the test error of an SVM classifier (linear) trained with low cost features and $\gamma_2$ denotes test error of SVM classifier trained using both low and high-cost features (cf. Section \ref{sec:Experiments}). The last column lists $\delta_{12}:=\Prob{Y^1=Y, Y^2\neq Y}$, the probability that second sensor misclassifies an instance that is correctly classified by the first sensor. Strong dominance is the notion that suggests that this probability is zero. We find in these datasets that $\delta_{12}$ is small thus justifying our notion. In general we have found this behavior is representative of other cost-associated datasets. Note that strong dominance is not merely a consequence of improved accuracy with availability of more features. It is related to better {\it recall rates} of high-cost features relative to low-cost features. %Strong dominance assumption implies that the collection of ''recalled examples'' with low-cost features is a subset of those recalled with high-cost features. 



We next show that strong dominance conditions ensures learnability. To this end,
let $\TSD = \{ \theta\in \TSA\,:\, \theta \text{ satisfies the strong dominance condition } \}$.
%\begin{thm}

%Let $\TSD = \{ \theta\in \TSA\,:\, \theta \text{ satisfies the strong dominance condition } \}$.
\begin{thm}
\label{thm:tsdlearnable}
The set $\TSD$ is learnable.
\end{thm}
We start with a proposition that will be useful beyond the proof of this result.
In this proposition, $\gamma_i = \gamma_i(\theta)$ for $\theta \in \TSA$ and $(Y,Y^1,\dots,Y^K) \sim \theta$.
\begin{prop}\label{prop:gammadiff}
For any $i,j\in [K]$, $\gamma_i - \gamma_j = \Prob{Y^i\ne Y^j} - 2\Prob{ Y^j \ne Y, Y^i=Y}$.
\end{prop}

The proof motivates the definition of weak dominance, a concept that we develop next through a series of smaller
propositions. In these propositions, as before $(Y,Y^1,\dots,Y^K) \sim P$ where $P\in M_1(\{0,1\}^{K+1})$,
 $\gamma_i = \Prob{Y^i \ne Y}$, $i\in [K]$, and $C_i = c_1 + \cdots + c_i$.
We start with a corollary of \cref{prop:gammadiff}
\begin{cor}
\label{cor:gammadiff}
Let $i<j$. Then $0\le \gamma_i -\gamma_j \le \Prob{Y^i\ne Y^j}$.
\end{cor}
\begin{prop}
\label{prop:ilej}
Let $i<j$. Assume 
\begin{align}
\label{eq:cond1}
C_j - C_i \not\in [\gamma_i - \gamma_j, \Prob{Y^i\ne Y^j} )\,.
\end{align}
Then $\gamma_i + C_i \le \gamma_j + C_j$ if and only if $C_j - C_i \ge \Prob{Y^i\ne Y^j}$.
\end{prop}
\begin{proof}
\noindent $\Rightarrow$: From the premise, it follows that $C_j - C_i \ge \gamma_i - \gamma_j$.
Thus, by~\eqref{eq:cond1}, $C_j - C_i \ge \Prob{Y^i\ne Y^j}$.
\noindent $\Leftarrow$: We have $C_j - C_i \ge \Prob{Y^i \ne Y^j} \ge \gamma_i -\gamma_j$, where the last
inequality is by \cref{cor:gammadiff}.
\end{proof}
\begin{prop}
\label{prop:jlei}
Let $j<i$. Assume
\begin{align}
\label{eq:cond2}
C_i - C_j \not\in (\gamma_j - \gamma_i, \Prob{Y^i \ne Y^j} ]\,.
\end{align}
Then, $\gamma_i + C_i \le \gamma_j + C_j$ if and only if $C_i - C_j \le \Prob{Y^i \ne Y^j}$.
\end{prop}
\begin{proof}
\noindent $\Rightarrow$: The condition $\gamma_i + C_i \le \gamma_j + C_j$ implies that $\gamma_j -\gamma_i \ge C_i - C_j$.
By \cref{cor:gammadiff} we get $\Prob{Y^i \ne Y^j} \ge C_i - C_j$.
\noindent $\Leftarrow$: Let $C_i - C_j \le \Prob{Y^i \ne Y^j}$. Then, by \eqref{eq:cond2}, $C_i - C_j \le \gamma_j - \gamma_i$.
\end{proof}
These results motivate the following definition:
\begin{defi}[Weak Dominance]
	\label{dfn:WDP}
	An instance $\theta \in \TSA$  is said to satisfy the \emph{weak dominance property} if 
	for $i = a^*(\theta)$,
	\begin{align}
	\label{eq:wd} \forall j>i\,\,: \,\, C_j - C_i \ge \Prob{Y^i\ne Y^j}\,.
	\end{align}
We denote the set of all instances in $\TSA$ that satisfies this condition by $\TWD$.	
\end{defi}
Note that $\TSD\subset \TWD$ since for any $\theta\in \TSD$, any $j>i = a^*(\theta)$, on the one hand $C_j - C_i \ge \gamma_i - \gamma_j$, while on the other hand, by the strong dominance property, $\Prob{Y^i\ne Y^j} = \gamma_i - \gamma_j$.

We now relate weak dominance to the optimality condition described in Eq.~\eqref{eqn:interp_opt}. Weak dominance can be viewed as a more stringent condition for optimal actions. Namely, for an action to be optimal we also require that the marginal cost be larger than marginal \emph{absolute} error:
\begin{equation} \label{eqn:interp_WD}
\underbrace{C_j - C_i}_{\text{Marginal Cost}} \geq \underbrace{ E \left [ \left | \ind{Y_t \ne Y_t^i} - \ind{Y_t \ne Y_t^j} \right | \right ]}_{\text{Marginal Absolute Error}},\,\,\, \forall \, j \geq i\,.
\end{equation}
The difference between marginal error in Eq.~\eqref{eqn:interp_opt} and marginal absolute error is the presence of the absolute value. We will show later that weak-dominant set is a maximal learnable set, namely, the set cannot be expanded while ensuring learnability.


We propose the following action selector $\awd: M_1(\{0,1\}^K)  \to [K]$:
\begin{defi}\label{def:awd}
For $P_S \in M_1(\{0,1\}^K) $ let $\awd(P_S)$ denote the smallest index $i\in [K]$ such that
\begin{subequations}
\begin{align}
\forall j<i \,\,:\,\, C_i - C_j < \Prob{ Y^i \ne Y^j }\,, \label{eq:wd1}\\ 
\forall j>i \,\,:\,\, C_j - C_i \ge \Prob{ Y^i \ne Y^j }\,, \label{eq:wd2}
\end{align}
\end{subequations}
where $C_i = c_1+\cdots + c_i$, $i\in [K]$ and $(Y^1,\dots,Y^K) \sim P_S$.
(If no such index exists, $\awd$ is undefined, i.e., $\awd$ is a partial function.)
\end{defi}
\begin{prop}
\label{prop:awdwelldef}
For any $\theta \in \TWD$ with $\theta = P_S\otimes P_{Y|S}$, $\awd(P_S)$ is well-defined.
\end{prop}

\begin{prop}
\label{prop:awdsound}
The map $\awd$ is sound over $\TWD$: In particular, for any
$\theta\in \TWD$ with $\theta = P_S\otimes P_{Y|S}$, $\awd(P_S)= a^*(\theta)$.
\end{prop}

\begin{cor}\label{cor:twdlearnable}
The set $\TWD$ is learnable.
\end{cor}
\begin{proof}
By \cref{prop:awdwelldef}, $\awd$ is well-defined over $\TWD$, while by \cref{prop:awdsound}, $\awd$ is sound over $\TWD$.
By \cref{prop:learnablemap}, $\TWD$ is learnable, as witnessed by $\awd$. \todoc{We should add definitions for these concepts..
namely, $\awd$ well-defined over $\TWD$, $\awd$ sound over $\TWD$, etc.}\todom[]{Csaba, you did this already!!}
\end{proof}
\begin{prop}
\label{prop:awdcorrectimplieswd}
Let $\theta \in \TSA$ and $\theta = P_S\otimes P_{Y|S}$ be such that $\awd$ is defined for $P_S$
and $\awd(P_S) = a^*(\theta)$. Then $\theta \in \TWD$.
\end{prop}
\begin{proof}
Immediate from the definitions.
\end{proof}
An immediate corollary of the previous proposition is as follows:
\begin{cor}\label{cor:awdoutsideincorrect}
Let $\theta \in \TSA$ and $\theta = P_S \otimes P_{Y|S}$. 
Assume that $\awd$ is defined for $P_S$ and $\theta \not\in \TWD$. Then $\awd(P_S) \ne a^*(\theta)$.
\end{cor}
The next proposition states that $\awd$ is essentially the only sound action selector map defined for
 all instances derived from instances of $\TWD$:
\begin{prop}\label{prop:awdunique}
Take any action selector map $a: M_1( \{0,1\}^K ) \to [K]$ which is sound over $\TWD$.
Then, for any $P_S$ such that $\theta = P_S\otimes P_{Y|S}\in \TWD$ with some $P_{Y|S}$,
 $a(P_S) = \awd(P_S)$.
\end{prop}

The next result shows that
the set $\TWD$ is essentially a maximal learnable set in $\mathrm{dom}(\awd)$:
\begin{thm}
Let $a: M_1(\{0,1\}^K) \to [K]$ be an action selector map
such that $a$ is sound over the instances of $\TWD$.
Then there is no instance $\theta = P_S\otimes P_{Y|S} \in \TSA\setminus \TWD$ such that 
$P_S\in \mathrm{dom}(\awd)$, the optimal action of $\theta$ is unique
\todoc{It would be nice to remove this uniqueness assumption, but I don't see how this could be made to work.}
 and $a(P_S) = a^*(\theta)$.
\end{thm}
Note that $\mathrm{dom}(\awd)\setminus \{ P_S \,:\, \exists P_{Y|S} \textrm{ s.t. } P_S \otimes P_{Y|S} \in \TWD \} \ne \emptyset$, i.e., the theorem statement is non-vacuous.
In particular, for $K=2$, consider $(Y,Y^1,Y^2)$ such that $Y$ and $Y^1$ are independent and $Y^2 = 1-Y^1$, we can see that the resulting instance gives rise to $P_S$ which is in the domain of $\awd$ for any $c\in \R_+^K$ (because here $\gamma_1 = \gamma_2 = 1/2$, thus $\gamma_1 - \gamma_2 = 0$ while $\Prob{Y^1\ne Y^2}=1$).
\begin{proof}
Let $a$ as in the theorem statement. By~\cref{prop:awdunique}, $\awd$ is the unique sound action-selector map over $\TWD$.
Thus, for any $\theta = P_S\otimes P_{Y|S}\in \TWD$, $\awd(P_S) = a(P_S)$.
Hence, the result follows from \cref{cor:awdoutsideincorrect}.
\end{proof}
While $\TWD$ is learnable, it is not uniformly learnable, i.e., the minimax regret $\Regret_n^*(\TWD) = \inf_{\Alg} \sup_{\theta\in \TWD} \Regret_n(\Alg,\theta)$ over $\TWD$ grows linearly:
\begin{thm}
\label{thm:nonunif}
$\TWD$ is not uniformly learnable:
$\Regret_n^*(\TWD) = \Omega(n)$.
\end{thm}
\begin{proof}
