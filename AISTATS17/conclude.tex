The paper describes a novel approach for unsupervised \ses. These types of problems arise in a number of healthcare and security applications. In these applications is that we have a collection of tests that is typically organized in a hierarchical architecture wherein test results are acquired in a sequential fashion. The goal is to identify that best balance accuracy and test-costs. The main challenge in these applications is that ground-truth annotated examples are unavailable and it is often difficult to acquire them in-situ. We proposed a novel approach for \ses and introduced a novel notion of weak and strong dominance properties. We showed that weak dominance condition is maximal in that violation of this condition leads to loss of learnability. Our experiments demonstrate that weak dominance does hold in practice for real datasets. Furthermore, for these datasets there is little qualitative different between unsupervised selection and a supervised (bandit) setting. 


%\noindent
%{\bf Extensions:} We describe a few extensions here but omit details due to lack of space.
%
%\noindent
%{\it Tree-Architectures:}
%%It is straightforward to see that we can generalize our cascade model to a tree-architecture. 
%%The algorithm Alg.~\ref{alg:asym} and Alg.~\ref{alg:UCB} extends to trees. 
%We can deal with trees in an analogous fashion. Like for cascades we keep track of disagreements along each path. Under SD these disagreements in turn approximate marginal error. This fact is sufficient to identify the optimal sensor (see Eqn.~\ref{eqn:interp_opt}). Similarly our results also generalize to trees under WD condition. 
%
%\noindent
%{\it Context-Dependent Sensor Selection:}
%%Our results can also be generalized to specific context dependent cases as well. 
%Each example has a context $x \in \mathbb{R}^d$. A test is a mapping that takes (partial) context and maps to an output space. We briefly describe how to extend to context-dependent \ses. Analogous to the context-independent case we impose context dependent notions for SD and WD, namely, Eq.~\ref{eqn:DominanceCondition} and Eq.~\ref{eqn:WD} hold conditioned on each $x \in {\cal X}$. To handle these cases we let $\gamma_i(x)\triangleq \Pr(Y^{i} \neq Y)$ and $\gamma_{ij}(x) \triangleq \Pr(Y^{i} \neq Y^{j})$ denote the conditional error probability for the ith sensor and the conditional marginal error probability between sensor $i$ and $j$ respectively. Then the results can be generalized under a parameterized GLM model for disagreement, namely, the log-odds ratio $\log \frac{\gamma_{ij}(x)}{1-\gamma_{ij}(x)}$ can be written as $\theta_{ij}'x$ for some unknown $\theta_{ij} \in \mathbb{R}^d$.
%\begin{proof}