@article{MOR11_LinearlyParametrized_RusmevichientongTsitsiklis,
  title={Linearly Parameterized Bandits},
  author={Rusmevichientong, Paat and Tsitsiklis, John N},
  journal={Mathematics of Operations Research},
  volume={35},
  number={2},
  pages={395--411},
  year={2010},
  publisher={INFORMS}
}

@article{IC2000_AppleTasting_HelmboldLittlestoneLong,
	title={Apple Tasting},
	author={D. P. Helmboat and PN Littlestone and P.M. Long},
	journal={Journal of Information and Computation},
	volume={161},
	number={2},
	pages={85--139},
	year={2000},
	publisher={ELSEVIER}
}

@article{AAM85_Asymptotically_LaiRobbins,
  title={Asymptotically Efficient Adaptive Allocation Rules},
  author={Tze Leung Lai and Herbert Robbins},
  journal={Journal of Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Elsevier}
}
@inproceedings{NIPS10_ParametricBandits_FillipiCappe,
  title={Parametric bandits: The Generalized Linear Case},
  author={Sarah Filippi and Olivier Cappe and Aur{\'e}lien Garivier and Csaba Szepesv{\'a}ri},
  booktitle={Proceeding  of Advances in Neural Information Processing Systems},
  pages={586--594},
  year={2010}
}
@inproceedings{NIPS2011_ImprovedAlgorithms_AbbasiPalSzepes,
  title={Improved Algorithms for Linear Stochastic Bandits},
  author={Yasin Abbasi-Yadkori and D{\'a}vid P{\'a}l and Csaba Szepesv{\'a}ri},
  booktitle={Proceeding of Advances in Neural Information Processing Systems (NIPS)},
  pages={2312--2320},
  year={2011},
  
}
@inproceedings{NFDS2010_LearningMultiUser_GaiKrishnamachariJain,
  title={Learning Multiuser Channel Allocations in Cognitive Radio Networks: A Combinatorial Multi-armed Bandit Formulation},
  author={Yi Gai and Bhaskar Krishnamachari and Rahul Jain},
  booktitle={Proceeding of Symposium on New Frontiers in Dynamic Spectrum, 2010},
  pages={1--9},
  year={2010},
  organization={IEEE}
}
@inproceedings{AISTATS2011_ContextualBandits_ChuLiReyzinSchapire,
  title={Contextual Bandits with Linear Payoff Functions},
  author={Wei Chu and Lihong Li and Lev Reyzin and Robert E. Schapire},
  booktitle={Proceeding of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={208--214},
  year={2011}
}

@book{Book_IntroductionLinear_BertsimasTsitsiklis,
	author = {Dimitris Bertsimas and John N. Tsitsiklis},
	title = {Introduction to Linear Optimization},
	year = {2008},
	OPTedition = {edition},
	publisher = {Athena Scientific, Belmont, Massachusetts},
}

@article{JMLR02_UsingConfidenceBounds_Auer,
	title={Using Confidence Bounds for Exploitation-Exploration
	Trade-offs},
	author={P. Auer},
	journal={Journal of Machine Learning Research},
	volume={3},
	pages={397--422},
	year={2002},
}

@article{ML02_FiniteTimeAnalysis_AuerBianchiFischer,
	title={Finite-Time Analysis of Multiarmed Bandit Problem
	trade-offs},
	author={P. Auer and Nichol{\'o}-Cesa-Bianchi and Paul Fischer},
	journal={Journal of Machine Learning},
	volume={3},
	pages={235--256},
	year={2002},
	publisher={Springer}
}

@inproceedings{ICML15_CheapBandits_HanawalSaligramaValko,
	title={Cheap Bandits},
	author={M.K. Hanawal and V. Saligrama and M. Valko and R. Munos},
	booktitle={Proceeding of International Conference on Machine Learning (ICML)(to appear)},
	year={2015}
}


@inproceedings{Sigmetrics15_StochasticBanditsWithSideObservations_BuccapatnamEriyilmazShroff,
	title={Stochastic Bandits With Side Observation on Networks},
	author={S. Buccapatnam and A. Eryilmaz and N. B. Shroff},
	booktitle={Proceeding of Sigmetrics},
	year={2014}
}

@book{Book_RecommenderSystem_ZankerFelferningFriedtich,
	author = {D. Jannach and M. Zanker and A. Felfernig  and G. Friedrich},
	title = {Recommender Systems: An Introduction},
	year = {2010},
	OPTedition = {edition},
	publisher = {Cambridge University
	Press},
}


@INPROCEEDINGS{COLT08_RegretBoundsForSleeping_KelinbergMizilSharma,
	author = {Robert D. Kleinberg and Alexandru Niculescu-mizil and Yogeshwer Sharma},
	title = {Regret bounds for sleeping experts and bandits},
	booktitle = {Proceedings of Conference on Learning Theory},
	year = {2008},
	pages = {425--436}
}

@article{AMS1952_SomeAspectsOfSequenntial_Robbins,
	author = {Herbert Robbins},
	journal = {Bulletin of the American Mathematics Society},
	keywords = {bandits},
	pages = {527--535},
	title = {Some aspects of the sequential design of experiments},
	volume = {58},
	year = {1952}
}

@inproceedings{ICML14_SpectralBandits_ValkoMunos,
	author = {Michal Valko  and R\'{e}mi Munos  and Branislav Kveton and Tom\'{a}\v{s} Koc\'{a}k },
	booktitle = {Proceeding of International Conference on Machine Learning (ICML)},
	title = {Spectral Bandits for Smooth Graph Functions},
	year = {2014}
}


@inproceedings{COLT09_ForcedExplorationBased_YadkoriAntosSzepe,
	author = {Y. Abbasi-Yadkori and A. Antos and Cs. Szepesv\'{a}ri},
	booktitle = {Proceeding COLT workshop on On-line Learning with Limited Feedback },
	title = {Forced-exploration based algorithms for playing
	in stochastic linear bandits},
	year = {2009}
}

@article{Algorithmica2003_ReinforcementLearning_AbeBiermanLong,
	author = {N. Abe, and A. W. Biermann, and P. M. Long},
	journal = {Algorithmica},
	keywords = {bandits},
	pages = {263--293},
	title = {Reinforcement learning with immediate rewards and linear hypotheses},
	volume = {37},
	year = {2003}
}

@inproceedings{UAI09_ExploringCompactReinforment_WalshSzitaLittman,
	author = {T. J. Walsh and I. Szita and C. Diuk, and M. L. Littman},
	booktitle = {Proceeding of Uncertainty in Artificial Intelligence (UAI)},
	title = {Exploring compact reinforcement-learning representations with linear regression},
	year = {2009}
}


@inproceedings{ICML99_AssociativeReinformentLearning_AbeLong,
	author = {N. Abe and P. M. Long},
	booktitle = {Proceeding of International Conference on Machine Learning (ICML)},
	title = {Associative reinforcement learning using linear probabilistic concepts},
	year = {1999}
}

@inproceedings{COLT09_MinimacPoliciesForAdversarial_AudibertBubeck,
	author = {J.-Y. Audibert and S. Bubeck},
	booktitle = {Proceedings of the Annual Conference on Learning Theory
	(COLT)},
	title = {Minimax policies for adversarial and stochastic
	bandits},
	year = {2009}
}

@article{AAP1995_SampleMeanBased_Agarwal,
	author = {R. Agrawal},
	journal = {Advances in Applied Probability},
	keywords = {bandits},
	pages = {1054--1078},
	title = {Sample mean based index policies with
	$O(log n)$ regret for the multi-armed bandit problem},
	volume = {27},
	year = {1995}
}

@inproceedings{AISTATS12_BanditTheoryMeetsCS_CarpentierMunos,
	author = {Alexandra Carpentier and R\'{e}mi Munos},
	booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics
	(AISTATS)},
	title = {Bandit theory meets compressed
	sensing for high dimensional stochastic linear bandit},
	year = {2012}
}

@inproceedings{AISTATS12_Online-to-confidence-set_AbbasiPalSzepes,
	author = {Y. Abbasi-Yadkori and D. Pal and Cs. Szepesv\'{a}ri},
	booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics
	(AISTATS)},
	title = {Online-to-confidence-set conversions
	and application to sparse stochastic bandits},
	year = {2012}
}

@book{Book_IPredictionLearningAndGames_BianchiLugosi,
	author = {Nicol\'{o} Cesa-Bianchi and G\'{a}bor Lugosi},
	title = {Prediction, Learning, and Games},
	year = {2006},
	OPTedition = {edition},
	publisher = {Cambridge University Press, New York},
}

@article{JMLR2010_RegretBoundsAndMinimax_AudibertBubeck,
	author = {J.-Y. Audibert and S. Bubeck},
	journal = {Journal of Machine Learning Research},
	keywords = {bandits},
	pages = {2635--2686},
	title = {Regret bounds and minimax policies under
	partial monitoring},
	volume = {11},
	year = {2010}
}

@article{TCS09_ExplorationExploitationTradeOff_AudibertMunosSzepes,
	author = {Jean-Yves Audibert and R\'{e}mi Munos and Csaba Szepesv\'{a}ri},
	journal = {Theoretical Computer Science},
	keywords = {bandits},
	pages = {1876–1902},
	title = {Exploration–exploitation tradeoff using variance estimates in multi-armed bandits},
	volume = {410},
	year = {2009}
}
